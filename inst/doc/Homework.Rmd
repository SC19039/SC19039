---
title: "Homework"
author: '19039'
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to Homework}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# The homework 1
## Questions
   Give three simple examples including text,figures,and tables by using knitr.



## Texts

   Some simple codes are written as follows:
   ```{r}
   x1<-c(1.2,2.6, 3.3,4.5,6.1,6.9,7.5,8.4,9.8,10.1,11.2,12.8,13.5,14.4,15.4,16.7)
   x2<-c(0.98,0.87,0.85,0.80,0.74,0.69,0.65,0.60,0.52,0.49,0.44,0.39,0.28,0.19,0.15,0.08)
   x3<-c(12.6,13.1,14,15.1,16.8,17.2,18.3,19.1,20.1,21.2,22.3,23.5,24.6,25.4,26.7,27.8)
   y<-c(53,56,57,58.9,59.9,60.4,61.9,62.8,63.9, 65, 66.4,68.2,69.9,70.8,72.2,74)
   fun1<-lm(y~I(x1^2)+x1+x2+x3)
   fun1
   summary(fun1)$coef 
   ```
## table
   Let's take a look at the data about the island by using a table.
```{r islands}
knitr::kable(head(islands))
```

   The head function means that only the first six data are taken.
   Let us see data about rock:
   
```{r rock}
knitr::kable(head(rock))
```

## Figure
  
   First ,the graph of fun1 is shown as follows:
   
```{r,echo=FALSE}
par(mar=c(1,1,1,1))
par(mfrow=c(2,2))
plot(fun1)
```
   
   The `echo = FALSE` parameter are aimed at preventing printing of the R code .
   Another example:
   
```{r}
x4=matrix(rnorm(100,mean=1.5,sd=2),ncol=2)
plot(x4)
```
   
   We get a set of data with a mean of 1.5 and a variance of 2.


# The homework 2

## 1 Questions
Learn to use r to generate random numbers.Here we solve three questions about  Rayleigh distribution, normal location mixture,Wishart distribution .

## 2 Rayleigh distribution.( Exercises 3.4) 
First,we clear variable by using rm(list = ls()).Then we write a function to get  a nxd matrix.We get  D-dimensional independent random variables.
```{r}
#Clear variable
rm(list = ls())
# Write a function to generate n random vectors from MVN(mu, Sigma)
wf1 <- function(n, mu, Sigma) {
 # dimension is inferred from mu and Sigma 
  di <- length(mu)
  #Eigenvalue decomposition for sigma
  eva <- eigen(Sigma, symmetric = TRUE)
  #Get the value of the eigenvalue
  lam <- eva$values
  #Get the vector of the eigenvalue
  Ve <- eva$vectors
  #Here we use sqrt(lambda) to make sure Z
  C <- Ve %*% diag(sqrt(lam)) %*% t(Ve)
  Y <- matrix(rnorm(n*di), nrow = n, ncol = di)
  #X is the matrix we need
  X <- Y %*% C + matrix(mu, n, di, byrow = TRUE)
}
```
In order to call this function, we write a loop as follows.
In the loop, we take the variance equal to 1,3,8,15.We draw a histogram and compare it with the density function curve.The density function formula is
$$f(x)=\frac{x}{\sigma^{2}} e^{-x^{2} /\left(2 \sigma^{2}\right)}$$

```{r}
#Initial value
mu <- c(0, 0)
#Preparing to draw four graphs
par(mar=c(1,1,1,1))
par(mfrow=c(2,2))
# To get four graphs,we need a for loop.
for (i in c(1,3,8,15)){
  Sigma <- matrix(c(i, 0, 0, i), nrow = 2, ncol = 2)
  X3 <- wf1(1000, mu, Sigma)
  cov(X3);#Covariance
  a3<-X3^2;
  #calculate value
  a<-sqrt(a3[,1] +a3[,2]);
  #Set the abscissa
  break3=seq(0,20,0.3);
  #Drawing histogram
  x1=break3
  hist(a,prob=TRUE,breaks=break3,main = i,col = 'yellow');
  #Density function curve
  lines(x1,x1*exp(-x1*x1/2/i)/(i))
}
```

## Analysis
   The histogram is close to the density function curve. As the variance increases, the density function curve gradually becomes flat.

## 3 normal location mixture.( Exercises 3.11) 
  First,we generate a graph with p1=0.75 and 1-p1=0.25
```{r}
n<-1e4
#Generating a normal distribution
y1 <- rnorm(n,mean=0)
y2 <- rnorm(n,mean=3)
#Assign value to p1
r <- sample(c(0,1),n,replace=TRUE,prob = c(0.25,0.75))
z1 <- r*y1+(1-r)*y2
x2=seq(-5,10,0.2)
#Draw a histogram
hist(z1,prob=TRUE,breaks = seq(-5,15,0.2),col='red')
#Draw a density function curve
lines(x2,0.75*exp(-x2*x2/2)/sqrt(2*pi)+0.25*exp(-(x2-3)*(x2-3)/2)/sqrt(2*pi))
```
From the graph,we can see that there is a elbow in it.In order to make the change more obvious, we wrote a cycle to draw nine pictures. The value of probability p1 is taken from 0.1 to 0.5.
```{r}
#A function of drawing picture with p1
wf2<-function(n,p1){
y1 <- rnorm(n,mean=0)
y2 <- rnorm(n,mean=3)
#Assign value to p1
r <- sample(c(0,1),n,replace=TRUE,prob = c(p1,1-p1))
z <- r*y1+(1-r)*y2}
#Prepare to draw nine pictures
par(mar=c(1,1,1,1))
par(mfrow=c(3,3))
#A loop to draw picture
for(i in seq(2,10,1)){
p2=i/20
z<-wf2(10000,p2)
x3=seq(-5,10,0.2)
#Draw a histogram
hist(z,prob=TRUE,breaks = seq(-5,10,0.3),main = p2,col='blue') 
#Density function curve
lines(x3,(1-p2)*exp(-x3*x3/2)/sqrt(2*pi)+p2*exp(-(x3-3)*(x3-3)/2)/sqrt(2*pi))}
```

## Analysis
From the graph,we know that the graph begin to produce bimodal mixtures as p1=0.25.When p1=0.5,There are two equal doublets. 

## 4 Wishart distribution.( Exercises 3.18) 
We write a function to produce a random sample  from a Wishart distribution.The function wish has two paraments:n and sigma.We can get a sample after we input n and sigma.
```{r}
wish<-function(n,sigma1){
#Cholesky algorithm
chol1<-chol(sigma1)
#Get dimension of chol1
dim1=dim(chol1)
A=matrix(nrow=dim1[1],ncol=dim1[2])
# produce matrix A
for(i in 1:dim1[1]){
  for (j in 1:dim1[2]){
    if (i<j){A[i,j]=0}
    else if(i>j){A[i,j]=rnorm(1)}
    else{A[i,j]=sqrt(rchisq(1,n-i+1,ncp=0))}
  }
}
X=t(chol1)%*%A%*%t(A)%*%chol1}
```
We can get a matrix X by $X=LAA^\mathrm{T}L^\mathrm{T}$,where $AA^\mathrm{T}$has a $W_{d}(I_{d},n)$ distribution.Let$A=(A_{ij})$ be a lower triangular
d × d random matrix with independent entries satisfying:
$$
\begin{array}{l}{\text { 1. } A_{i j} \stackrel{\text { iid }}{\sim} N(0,1), i>j} \\ {\text { 2. } A_{i i} \sim \sqrt{\chi^{2}(n-i+1)}, i=1, \ldots, d}\end{array}
$$
Then,$X=LAA^\mathrm{T}L^\mathrm{T}\sim\ W_{d}(\sum,n)$
```{r}
sigma1<-matrix(c(5,1,1,5),ncol = 2)
n=10
wi<-wish(n,sigma1)
wi
```
We set n=10 and 
$$\sum=\begin{matrix} 
5&1\\
1&5\end{matrix}$$
And we get matrix X:
```{r,echo=FALSE}
wi
```



# The  homework 3

## 1.Questions
1.Learn to use Monte Carlo method to calculate Integration.

2.Learn to use four methods to reduce variance and select the best one.

## 2.Question 1(exercise 5.1)
$\textbf{question 1:}$

Compute a Monte Carlo estimate of
$$
\int_{0}^{\pi / 3} \sin (t) d t
$$
and compare your estimate with the exact value of the integral.

$\textbf{Solution process:}$

$\textbf{step1}$:give the value of m;

$\textbf{step2}$:generate random numbers;

$\textbf{step3}$:take average to approximate the expectatiion;

$\textbf{step4}$:calculate integration by hand.

$\textbf{step5}$:compare two value.
Here is the experiment result of n=10000.

```{r}
n<-1e4;
#generate 10000  random numbers between 0 and pi/3
y<-runif(n,min=0,max=pi/3);
#take average
a1<-mean(sin(y)*pi/3);
print(c(a1,0.5))
```
We draw a graph to see the rusult
Let us set n=1000000 and run it again.

```{r,echo=FALSE}
n<-1e6;
#generate 10000  random numbers between 0 and pi/3
y<-runif(n,min=0,max=pi/3);
#take average
a1<-mean(sin(y)*pi/3);
print(c(a1,0.5))
```
$\textbf{Analysis}$

 As the number of experiments increases, the estimated value will be close to the true value.
 
## 3.Question 2(exercise 5.10)
$\textbf{question 2:}$
Use Monte Carlo integration with antithetic variables to estimate:
$$\int_{0}^{1}\frac{e^{-x}}{1+x^2}dx,$$
and find the approximate reduction in variance as a percentage of the variance
without variance reduction.

$\textbf{Solution process:}$

$\textbf{step1}$:We write a function to get the estimated value by single Monte Carlo experiment.Every time we get a value.
```{r}
yu<-function(m){
z<-runif(m,min=0,max = 1);
z1<-exp(-z)/(1+z^2)*1
z2<-mean(z1)
z2}
```

$\textbf{step2}$:We write second function by using antithetic variable method.

```{r}
anti<-function(m){
m1<-m/2
x<-runif(m1,min=0,max = 1);
x1<-exp(-x)/(1+x^2)*1
x2<-exp(-(1-x))/(1+(1-x)^2)*1
x3<-c(x1,x2)
x4<-mean(x3)
}
```

$\textbf{step3}$:Finally,we call 1000 times function .After that,we get the value of aa and bb.Both dimension of them are 1000.We can compare variance of them and get a percentage.

```{r}
iter=1000
aa=numeric(iter)
bb=numeric(iter)
for (i in 1:iter) {
  aa[i]=yu(10000)
  bb[i]=anti(10000)
}
print(c(sd(bb),sd(aa),sd(bb)/sd(aa)))
```

To see the result clearly,we draw an image. The first 100 values are taken from aa1 and bb1.
```{r}
aa1=aa[1:100]
bb1=bb[1:100]
plot(aa1,type='l',xlab='aa1 and bb1',ylab='',col='red',main='make a comparision')
lines(bb1,col='blue')

```

$\textbf{Analysis}$
   The variance ratio of the two methods is about 0.2.We reduce variance successfully even if the effect is not very well. From the above picture ,we can also see that,the later one has a smaller variance.

## 4.Question 3(exercise 5.15)
$\textbf{question 3:}$

Obtain the stratified importance sampling estimate in Example $5.13$ and compare it with the result of Example $5.10$.

In Example $5.10$, we select function $f_{3}(x)=e^{-x}/(1-e^{-1}),0<x<1$ as best result.From that simulation,we get $\hat{\theta}=0.5257801$ and estimated standard error $0.0970314$ by $10000$  replicates.
Now we use  stratified importance sampling. $[0,1]$ is dixided into five subintervals.And on the $j^{th}$ subinterval variables are generated from the density
$$
\frac{5 e^{-x}}{1-e^{-1}}, \quad \frac{j-1}{5}<x<\frac{j}{5}
$$
From the conditional density $f_{j}$ of $x$,we know that $f(x)=\frac{1}{5}f_{j}(x)=\frac{ e^{-x}}{1-e^{-1}}$
Here is the process step:
step1:set the value of m2,K,N,sj,T,mat1,ssd.
step2:write two functions of $g(x)$ and $f(x)$ Preparing for the loop.
step3: start loop :(1)divide the interval (0,1) into five subintervals and calculate the values of $x$ by inverse transform method.
(2)calculate $\hat{\theta_{j}}$ by importance sampling. 
(3)take the averaage of T and ssd.
step4:get the value of $\theta$ and its variance


```{r}
m2<-100000;
k<-5
N<-50#number of iteration
sj<-numeric(m2/k)
T<-numeric(k)
mat1=numeric(N)
sd=numeric(k)
ssd=numeric(N)
g<-function(x)exp(-x)/(1+x^2)*(x>0)*(x<1)
  #{exp(-x-log(1+x^2))*(x>0)*(x<1)}
f<-function(x)
{-log(1-x*(1-exp(-1)))}
duan=c(0,0.2,0.4,0.6,0.8,1)
for(i in 1:N){
  for(j in 1:5){
    sj<-f(runif(m2/k,duan[j],duan[j+1]))#generate x
    T[j]<-mean(5*g(sj)/(5*exp(-sj)/(1-exp(-1))))#每段均值
    sd<-sd(g(sj)/(exp(-sj)/(1-exp(-1))))
    }
  mat1[i]<-mean(T)
  ssd[i]<-mean(sd)
}  
mean(mat1)
mean(ssd)
```
The value of $\theta$ is about 0.524 and the variance is 0.03.The later is less than the value by importance sampling,which makes me interested.
Here is some extra work I had done.
I set $\mathbf{k=1}$ and run. Of course,the value is equal to before.

```{r,echo=FALSE}
m2<-100000;
k<-1
N<-50#number of iteration
sj<-numeric(m2/k)
T<-numeric(k)
mat1=numeric(N)
sd=numeric(k)
ssd=numeric(N)
g<-function(x)exp(-x)/(1+x^2)*(x>0)*(x<1)
  #{exp(-x-log(1+x^2))*(x>0)*(x<1)}
f<-function(x)
{-log(1-x*(1-exp(-1)))}
duan=c(0,1)
for(i in 1:N){
  for(j in 1:1){
    sj<-f(runif(m2/k,duan[j],duan[j+1]))#generate x
    T[j]<-mean(5*g(sj)/(5*exp(-sj)/(1-exp(-1))))#每段均值
    sd<-sd(g(sj)/(exp(-sj)/(1-exp(-1))))
    }
  mat1[i]<-mean(T)
  ssd[i]<-mean(sd)
}  
mean(mat1)
mean(ssd)
```

I set $\mathbf{k=2}$ and run:
```{r,echo=FALSE}
m2<-100000;
k<-2
N<-50#number of iteration
sj<-numeric(m2/k)
T<-numeric(k)
mat1=numeric(N)
sd=numeric(k)
ssd=numeric(N)
g<-function(x)exp(-x)/(1+x^2)*(x>0)*(x<1)
  #{exp(-x-log(1+x^2))*(x>0)*(x<1)}
f<-function(x)
{-log(1-x*(1-exp(-1)))}
duan=c(0,0.5,1)
for(i in 1:N){
  for(j in 1:2){
    sj<-f(runif(m2/k,duan[j],duan[j+1]))#generate x
    T[j]<-mean(5*g(sj)/(5*exp(-sj)/(1-exp(-1))))#每段均值
    sd<-sd(g(sj)/(exp(-sj)/(1-exp(-1))))
    }
  mat1[i]<-mean(T)
  ssd[i]<-mean(sd)
}  
mean(mat1)
mean(ssd)
```
Last we set $\mathbf{k=10}$ and run:

```{r,echo=FALSE}
m2<-100000;
k<-10
N<-50#number of iteration
sj<-numeric(m2/k)
T<-numeric(k)
mat1=numeric(N)
sd=numeric(k)
ssd=numeric(N)
g<-function(x)exp(-x)/(1+x^2)*(x>0)*(x<1)
  #{exp(-x-log(1+x^2))*(x>0)*(x<1)}
f<-function(x)
{-log(1-x*(1-exp(-1)))}
duan=c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1)
for(i in 1:N){
  for(j in 1:10){
    sj<-f(runif(m2/k,duan[j],duan[j+1]))#generate x
    T[j]<-mean(5*g(sj)/(5*exp(-sj)/(1-exp(-1))))#每段均值
    sd<-sd(g(sj)/(exp(-sj)/(1-exp(-1))))
    }
  mat1[i]<-mean(T)
  ssd[i]<-mean(sd)
}
mean(mat1)
mean(ssd)

```
To make the result clear ,a form is created:

```{r}
k.value<-c(1,2,5,10)
mean.value<-c(0.524,0.524,0.524,0.524)
sd.value<-c(0.0968,0.0692,0.0307,0.0156)
knitr::kable(cbind(k.value,mean.value,sd.value))
```

$\textbf{Analysis}$
From the form above we can know that stratified importance sampling can get a smaller variance comparing with importance sampling, and  the value of $\theta$ is similar. As the number of divided regions increases,the variances decrease.We can get a smaller variance .




# The homework 4

## Questions

6.5 Suppose a $95%$ symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarilyequal to $0.95$. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^{2}(2)$ data with sample size $n = 20$. Compare your t-interval results with the simulation results in Example $6.4$. (The t-interval should be more robust to departures from normality than the interval for variance.)

6.6 Estimate the $0.025$, $0.05$, $0.95$, and $0.975$ quantiles of the skewness$\sqrt(b_{1})$ under
normality by a Monte Carlo experiment. Compute the standard error of the estimates from $(2.14)$ using the normal approximation for the density (with exact variance formula). Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt(b_{1})\thickapprox N(0,6/n)$


## Question 1
$\textbf{1.Thought}$

According to the formula

$$
\bar{x} \pm t_{1-\alpha / 2}(n-1) s / \sqrt{n}
$$
we can cluculate 95% confidence interval of $x$.Then we compare the average value of $\chi^{2}(2)$,which is 2,with Upper and lower bound.
We do it 10000 times and take average to get  proportion.

$\textbf{2.Program}$

First, a function is written to get confidence interval.

```{r}
wf1<-function(n,alpha){
x <- rchisq(n,2)
UCL11 <- mean(x)+sd(x) *qt(alpha/2,n-1)/ sqrt(n)
UCL12<-mean(x)+ sd(x) *qt(1-alpha/2,n-1)/ sqrt(n)
c(UCL11,UCL12)
}
```

Then, A loop of 10000 times is done to calculate the probablity of UCL11<2 and UCL12>2,Which is our coverage probability.

```{r}
n=10000
data1=matrix(0,nrow = 2,ncol = n)
for(i in 1:n){
  data1[,i]=wf1(20,0.05)
}
length(which(data1[1,]<2&data1[2,]>2))/n
new.t1<-mean(data1[1,])
new.t2<-mean(data1[2,])
new.t1
new.t2
```

$\textbf{3.Analysis}$

The coverage probability is about $0.91$,which is lower than 0.95. The reason is that t distribution is a heavy tail distribution.

$\textbf{Compared with example 6.4}$,when the data comes from a normal distribution, the probability interval of coverage is approximately 95.6%. But when the data is not normally distributed, from the chi-square distribution, the t-distribution is still a good estimate.

## Question2 
$\textbf{1.Thought}$

I considered both large and small samples. Each case consists of three cycles. The first layer of the loop is a different q quantile. The second layer of the loop is a different n. The third layer of the cycle is repeated 1000 times.


$\textbf{2.Program}$

$\textbf{2.1 Small sample}$

1.The following function is used to calculate critical values,and it is solved in cv.

```{r}
cv<-function(alpha){
n <- c(10, 20, 30, 50, 100, 500)#sizes of samples
cv <- qnorm(alpha, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))#crit. values for each n
round(cv,5)#Five decimal places
}
```

2.This function is used to calculate sample skewness coeff.

```{r}
#write a function to compute the sample skewness coeff.
sk <- function(x) {
xbar <- mean(x)
m3 <- mean((x - xbar)^3)#molecule
m2 <- mean((x - xbar)^2)#for calculating Denominator
return( m3 / m2^1.5 )#return skewness
}

```

3.There are three loops.The first loop includes six different sample numbers.The second loop includes four quantiles.The third loop average 1000 results.

```{r}
n <- c(10, 20, 30, 50, 100, 500)
var<-p.reject <- matrix(0,4,length(n)) #to store sim. results
m <- 100000 #num. repl. each sim.
num<-0
for (alpha in c(0.9875,0.975,0.525,0.5125)){
    num<-num+1
    cv1<-cv(alpha)
    for (i in 1:length(n)) {
        sktests <- numeric(m) #test decisions
        for (j in 1:m) {
            x <- rnorm(n[i])
            #test decision is 1 (reject) or 0
            sktests[j] <- sum(abs(sk(x)) >= cv1[i] )
         }
         p.reject[num,i] <- mean(sktests) #proportion  rejected
         sigma<-sqrt(6*(n[i]-2) / ((n[i]+1)*(n[i]+3)))
         var[num,i]<-alpha*(1-alpha)/(n[i]*(exp(-cv1[i]^2/2/sigma^2)/(sigma*sqrt(2*pi)))^2)
    }
}
p.reject
var
```

$\textbf{ Analysis}$

In the case of small samples, we take the variance as $$
\operatorname{Var}(\sqrt{b_{1}})=\frac{6(n-2)}{(n+1)(n+3)}
$$. The result is very good, close to 0.025, 0.05, 0.95, and 0.975.As n increases, standard error of quantile becomes smaller.



# The homework 5

## Questions
$\textbf{6.7}$ Estimate the power of the skewness test of normality against symmetric $Beta(\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $t(ν)$?

$\textbf{6.A}$ Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α, when the sampled population is non-normal. The t-test is robust to mild departures from normality. Discuss the simulation results for the cases where the sampled population is (i) $\chi^{2}(1)$, (ii) Uniform$(0,2)$, and (iii) Exponential(rate=1). In each case, test $H_{0}:u=u_{0}$ vs $H_{0}:u\ne u_{0}$, where µ 0 is the mean of  $\chi^{2}(1)$, Uniform$(0,2)$, and Exponential(1), respectively.

$\textbf{Discussion}$ If we obtain the powers for two methods under a particular
simulation setting with $10,000$ experiments: say, $0.651$ for one
method and $0.676$ for another method. Can we say the powers
are different at $0.05$ level?

*What is the corresponding hypothesis test problem?

*What test should we use? Z-test, two-sample t-test, paired-t
test or McNemar test?

*What information is needed to test your hypothesis?


## Question 1

$\textbf{1.Thought}$

I analyzed the skewness of the Beta distribution from three cases:

*1.$\alpha\ne\beta$,$\alpha=2$ and $\beta$ ranges from 2 to 10.

*2.$\alpha=\beta$,and $\alpha$ ranges from 2 to 10.

*3.Mixed distribution,$(1 − \epsilon)Beta(\alpha_{1},\beta_{1}) + \epsilon Beta(\alpha_{2},\beta_{2})$

I analyzed the skewness of the t distribution from two cases:

*1.The freedom of t distribution ranges from 2 to 50

*2.Mixed distribution with t(2) and t(80),$(1 − \epsilon)t(2) + \epsilon t(80)$

$\textbf{2.Program}$ 

$\textbf{Work of Beta distribution}$

Prepare before starting.I draw two graph of Beta  distribution with different parameters.
```{r}
par(mar=c(1,1,1,1))
par(mfrow=c(1,2))
break1 = seq(0,1,0.02)

hist(rbeta(3000,10,10),prob=TRUE,break1,col = 'yellow')
lines(break1,dbeta(break1,10,10))

hist(rbeta(3000,2,6),prob=TRUE,breaks = seq(0,1,0.02),col = 'yellow')
lines(break1,dbeta(break1,2,6))
```


From the picture above ,we can know that when $\alpha=\beta$, the image is symmetrical and Skewness is equal to 0.When $\alpha\ne\beta$, the image is not symmetrical and Skewness is not equal to 0.

The following funtion sk() is used to calculate skewness.

```{r}
sk <- function(x) {
  #computes the sample skewness coeff.
  xbar <- mean(x)
  m3 <- mean((x - xbar)^3)
  m2 <- mean((x - xbar)^2)
  return( m3 / m2^1.5 )
}
```

$\textbf{Case1}$ $\alpha\ne\beta$,$\alpha=2$ and $\beta$ ranges from 2 to 10.

```{r}
alpha <- 0.05
n <- 30
m <- 1000
seq1 <-seq(2, 10, 0.2)
N <- length(seq1)
pwr <- numeric(N) #Store power value
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { 
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    x <- rbeta(30, 2, seq1[j])
    sktests[i] <- as.integer(abs(sk(x)) >= cv)
  }
  pwr[j] <- mean(sktests)
}
#plot power vs seq1
plot(seq1, pwr, type = "b",
     xlab = bquote(seq1), ylim = c(0,1),col='blue')
abline(h = 0.05, lty = 4) #Increase the confidence level of 0.05
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(seq1, pwr+se, lty = 3,col='violet')
lines(seq1, pwr-se, lty = 3,col='violet')
```

$\textbf{Analysis}$ :From the graph above ,we can infer that when $\alpha \ne\beta$,the distributon is skewed.There exists a elbow point when$\alpha=2,\beta=3.2$. When $\beta $ is less than $3.2$, the image is considered to have no skewness at a confidence level of 0.05.

$\textbf{Case2}$ $\alpha=\beta$,and $\alpha$ ranges from 2 to 10.

```{r}
alpha <- 0.05
n <- 30
m <- 1000
seq1 <-seq(2, 10, .2)
N <- length(seq1)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { 
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    x <- rbeta(30, seq1[j], seq1[j])
    sktests[i] <- as.integer(abs(sk(x)) >= cv)
  }
  pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(seq1, pwr, type = "b",
     xlab = bquote(seq1), ylim = c(0,0.2),col='blue')
abline(h = .05, lty = 4) #Increase the confidence level of 0.05
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(seq1, pwr+se, lty = 3,col='violet')
lines(seq1, pwr-se, lty = 3,col='violet')
```

$\textbf{Analysis}$:From the preparing work ,we know that the graph is Symmetrical when $\alpha=\beta$.Further, because power value is less than 0.05,from the above figure we kan know that the Beta distribution is not skewed.

$\textbf{Case3}$ Mixed distribution,$(1 − \epsilon)Beta(\alpha_{1},\beta_{1}) + \epsilon Beta(\alpha_{2},\beta_{2})$

```{r}
alpha <- 0.05
n <- 30
m <- 1000
seq2 <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(seq2)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { #for each epsilon
  e <- seq2[j]
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    par <- sample(c(2,10), replace = TRUE,
                    size = n, prob = c(1-e, e))
    x <- rbeta(30, par, par)
    sktests[i] <- as.integer(abs(sk(x)) >= cv)
  }
  pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(seq2, pwr, type = "b",
     xlab = bquote(seq2),col='blue')
abline(h = 0.05, lty = 3)
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(seq2, pwr+se, lty = 3,col='violet')
lines(seq2, pwr-se, lty = 3,col='violet')

```

$\textbf{Analysis}$:When $\epsilon$ is equal to 0 or 1,the result Obeys Beta distribution,otherwise the result is skewed.The variance of Beta(2,2) is bigger than Beta(2,10),so the highest point occurs when $\epsilon=0.8$

$\textbf{Work of t distribution}$

$\textbf{Case1}$The freedom of t distribution ranges from 2 to 50

```{r}
alpha <- .05
n <- 50
m <- 1000
seq1 <-seq(2, 50, 1)
N <- length(seq1)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { 
  #print(j)
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    x <- rt(n,seq1[j])
    sktests[i] <- as.integer(abs(sk(x)) >= cv)
  }
  pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(seq1, pwr, type = "b",
     xlab = bquote(seq1),ylim = c(0,1),col='blue')
abline(h = .05, lty = 3)
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(seq1, pwr+se, lty = 3,col='violet')
lines(seq1, pwr-se, lty = 3,col='violet')
```


$\textbf{Analysis}$ :When freedom is small,the t distribution is skewed because  Stochasticity of Generate randomness of random numbers. But when freedom is big,t distribution is close to normal distribution and it is approximately not skewed.


$\textbf{Case2}$ Mixed distribution with t(2) and t(80),$(1 − \epsilon)t(2) + \epsilon t(80)$
```{r}
alpha <- 0.05
n <- 30
m <- 1000
seq2 <- c(seq(0, .15, .01), seq(.15, 1, .05))
N <- length(seq2)
pwr <- numeric(N)
#critical value for the skewness test
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
for (j in 1:N) { #for each epsilon
  e <- seq2[j]
  sktests <- numeric(m)
  for (i in 1:m) { #for each replicate
    par <- sample(c(2,80), replace = TRUE,
                    size = n, prob = c(1-e, e))
    x <- rt(30, par)
    sktests[i] <- as.integer(abs(sk(x)) >= cv)
  }
  pwr[j] <- mean(sktests)
}
#plot power vs epsilon
plot(seq2, pwr, type = "b",
     xlab = bquote(seq2),col='green')
abline(h = 0.05, lty = 3)
se <- sqrt(pwr * (1-pwr) / m) #add standard errors
lines(seq2, pwr+se, lty = 3,col='yellow')
lines(seq2, pwr-se, lty = 3,col='yellow')

```

$\textbf{Analysis}$:When $\epsilon$ is equal to  1,the result Obeys t(80) and is not skewed,otherwise the result is skewed.When $\epsilon$ is equal to  0,the result Obeys t(2) and is  skewed.

## Question 2
$\textbf{1.Thought}$

When nominal significance level takes different values such as 0.025,0.05 and 0.1,I calculate  empirical Type I error against three distributions,and compare it with nominal significance level.

$Case1$:when the sampled population is $\chi^{2}(1)$:
```{r}
n <- 1000
mu0 <- 1
m <- 10000 #number of replicates
p <- numeric(m) #storage for p-values
chisq.hat<- numeric(3)
fw<-c(0.025,0.05,0.1)
for(i in 1:3){
   for (j in 1:m) {
      x <- rchisq(n, 1)
      ttest <- t.test(x, mu = mu0)
      p[j] <- ttest$p.value
   }
 chisq.hat[i]<- mean(p < fw[i])
}  
se.hat1 <- sqrt(chisq.hat * (1 - chisq.hat) / m)
print(c(chisq.hat, se.hat1))
```
The result of $\chi^{2}(1)$ is close to  nominal significance level .

$Case2$:when the sampled population is  Uniform(0,2):
```{r}
n <- 1000
alpha <- .05
mu0 <- 1
m <- 10000 #number of replicates
p <- numeric(m) #storage for p-values
unif.hat<- numeric(3)
fw<-c(0.025,0.05,0.1)
for(i in 1:3){
    for (j in 1:m) {
         x <- runif(n, 0,2)
         ttest <- t.test(x, mu = mu0)
         p[j] <- ttest$p.value
    }
  unif.hat[i]<- mean(p < fw[i])
}
se.hat2 <- sqrt(unif.hat * (1 - unif.hat) / m)
print(c(unif.hat, se.hat2))
```

The result of Uniform(0,2) is also close to  nominal significance level .

$Case3$:when the sampled population is exponential(rate=1):
```{r}
n <- 1000
alpha <- .05
mu0 <- 1
m <- 10000 #number of replicates
p <- numeric(m) #storage for p-values
exp.hat<- numeric(3)
fw<-c(0.025,0.05,0.1)
for(i in 1:3){
    for (j in 1:m) {
        x <- rexp(n, 1)
        ttest <- t.test(x, mu = mu0)
         p[j] <- ttest$p.value
    }
    exp.hat[i] <- mean(p < fw[i])
}

se.hat3 <- sqrt(exp.hat * (1 - exp.hat) / m)
print(c(exp.hat, se.hat3))
```
The result of exponential(rate=1) is also close to  nominal significance level .
```{r}
data.frame(fw,chisq.hat,unif.hat,exp.hat)

```

$Analysis$:From the table above ,we get that the when  sampled population is from  $\chi^{2}(1)$, Uniform(0,2),and exponential(rate=1),empirical Type I error rate of the t-test is approximately equal to the nominal significance level $\alpha$. The t-test is robust to mild departures from normality.

## Question 3

$\textbf{*Answer of question 1}$:

$H_{0}:$ Two powers are same,power1=power2

$H_{1}:$ Two powers are different,power$\ne$power2

$\textbf{*Answer of question 2}$:

Text:Paired-t test.

$z_{i}=pow_{1}-pow_{2}$

$\bar{z}=\frac{1}{n}\Sigma z_{i}$

Statistics:$T=\frac{\bar{z}\sqrt(n)}{s*}\sim t_{n-1}$

Rejected domain:$W_{0}={|T|=|\frac{\bar{z}\sqrt(n)}{s*}|>t_{n-1,\frac{\alpha}{2}}}$

$\textbf{*Answer of question 3}$:

Ten sets of experiments were performed, and the power values of the two methods were calculated for each experiment. Subtract them to get the value of z and calculate the variance of z.


# The homework 6
## Questions
$\textbf{7.6}$Efron and Tibshirani discuss the scor (bootstrap)test score data on 88 students who took examinations in five subjects [84, Table 7.1], [188, Table 1.2.1].The first two tests (mechanics, vectors) were closed book and the last three tests (algebra, analysis, statistics) were open book. Each row of the data frame is a set of scores (x i1 ,...,x i5 ) for the i th student. Use a panel display to display the scatter plots for each pair of test scores. Compare the plot with the sample correlation matrix. Obtain bootstrap estimates of the standard errors for each of the following estimates: $\hat{\rho}_{12}=\hat{\rho}(mec, vec)$,$\hat{\rho}_{34}=\hat{\rho}(alg,ana),$\hat{\rho}_{35}=\hat{\rho}(alg, sta),$\hat{\rho}_{45}=\hat{\rho}(ana, sta).


$\textbf{7.B}$Repeat Project 7.A for the sample skewness statistic. Compare the coverage rates for normal populations (skewness 0) and $\chi^{2}(5)$  distributions (positive skewness).

## Program

## Question 1
The covariance matrix is shown below:
```{r}
library(bootstrap) #for the score data
cor(scor)
#show a part of data
scor[1:5,]
```

Draw a scatter plot between each two exams

```{r}
par(mar=c(1,1,1,1))
par(mfrow=c(2,5))
for(i in 1:5){
  for(j in 1:5){
    if(i!=j & i<j){
    plot(scor[,i],scor[,j],col='red')}
  }
}
```

From the scatter plot we can see that there is a clear linear correlation between every two courses.

We calculate $\hat{\rho}_{12}$ as follows.A scatter plot and a histogram are drawn to show the relationship between the calculated result and the real result.
```{r}
N=300 # Initialize the numbers of replicates
hat.rho12<-numeric(N)
n<-nrow(scor)
for(i in 1:N){
  samp<-sample(1:n,n,replace = TRUE)
  hat.rho12[i]<-cor(scor$mec[samp],scor$vec[samp])
}
# Get Standard deviation of Correlation coefficient
hat.sd12<-mean(hat.rho12)
print(hat.sd12)
# real Correlation coefficient
real.rho12<-cor(scor$mec,scor$vec)
print(real.rho12)
#plot and compare with real Correlation coefficient
plot(hat.rho12,ylim = c(0,1),col='green')
abline(h = real.rho12, lty = 4,col='red')
#Draw a histogram and a true correlation coefficient vertical line
hist(hat.rho12)
abline(v=real.rho12,col='red',lwd=2)
```


We calculate $\hat{\rho}_{34}$ as follows.A scatter plot and a histogram are drawn to show the relationship between the calculated result and the real result.
```{r}
hat.rho34<-numeric(N)
for(i in 1:N){
  samp<-sample(1:n,n,replace = TRUE)
  hat.rho34[i]<-cor(scor$alg[samp],scor$ana[samp])
}
# Get Standard deviation of Correlation coefficient
hat.sd34<-mean(hat.rho34)
print(hat.sd34)
# real Correlation coefficient
real.rho34<-cor(scor$alg,scor$ana)
print(real.rho34)
#plot and compare with real Correlation coefficient
plot(hat.rho34,ylim = c(0,1),col='green')
abline(h = real.rho34, lty = 4,col='red')
#Draw a histogram and a true correlation coefficient vertical line
hist(hat.rho34)
abline(v=real.rho34,col='red',lwd=2)
```

We calculate $\hat{\rho}_{35}$ as follows.A scatter plot and a histogram are drawn to show the relationship between the calculated result and the real result.
```{r}
hat.rho35<-numeric(N)
for(i in 1:N){
  samp<-sample(1:n,n,replace = TRUE)
  hat.rho35[i]<-cor(scor$alg[samp],scor$sta[samp])
}
# Get Standard deviation of Correlation coefficient
hat.sd35<-mean(hat.rho35)
print(hat.sd35)
# real Correlation coefficient
real.rho35<-cor(scor$alg,scor$sta)
print(real.rho35)
#plot and compare with real Correlation coefficient
plot(hat.rho35,ylim = c(0,1),col='green')
abline(h = real.rho35, lty = 4,col='red')
#Draw a histogram and a true correlation coefficient vertical line
hist(hat.rho35)
abline(v=real.rho35,col='red',lwd=2)
```

We calculate $\hat{\rho}_{45}$ as follows.A scatter plot and a histogram are drawn to show the relationship between the calculated result and the real result.
```{r}
hat.rho45<-numeric(N)
for(i in 1:N){
  samp<-sample(1:n,n,replace = TRUE)
  hat.rho45[i]<-cor(scor$ana[samp],scor$sta[samp])
}
# Get Standard deviation of Correlation coefficient
hat.sd45<-mean(hat.rho45)
print(hat.sd45)
# real Correlation coefficient
real.rho45<-cor(scor$ana,scor$sta)
print(real.rho45)
#plot and compare with real Correlation coefficient
plot(hat.rho45,ylim = c(0,1),col='green')
abline(h = real.rho45, lty = 4,col='red')
#Draw a histogram and a true correlation coefficient vertical line
hist(hat.rho45)
abline(v=real.rho45,col='red',lwd=2)
```

$\textbf{Analysis}$: When the number of samples is small, multiple sampling experiments can be performed using the bootstrap method. The experimental results are very similar to the real results, indicating the effectiveness of the method.

## Question 2

Calculate the skewness with the following function
```{r}
sk <- function(x,j) {
  #computes the sample skewness coeff.
  xbar <- mean(x[j])
  m3 <- mean((x[j] - xbar)^3)
  m2 <- mean((x[j] - xbar)^2)
  return( m3 / m2^1.5 )
}
```


$\text{Normal distribution}$

We take a sample with a normal distribution of N(0,2), the sample size is 20, and each time we do bootstrap 1000 times, we cycle 1000 experiments. The coverage of the interval is calculated based on the experimental results.

```{r}
me<-0
n<-20
m<-1000
set.seed(12345)
library(boot)
nor.norm<-nor.basic<-nor.perc<-matrix(NA,m,2)
for (i in 1:m) {
  data.nor<-rnorm(n,0,2)
  nor.ske<-boot(data.nor,statistic=sk,R=1000)
  nor<- boot.ci(nor.ske,type=c("norm","basic","perc"))
  nor.norm[i,]<-nor$norm[2:3];
  nor.basic[i,]<-nor$basic[4:5];
  nor.perc[i,]<-nor$percent[4:5];
}
#Calculate the coverage probability of a normal distribution
cat('norm =',mean(nor.norm[,1]<=me & nor.norm[,2]>=me),
    'basic =',mean(nor.basic[,1]<=me & nor.basic[,2]>=me),
    'perc =',mean(nor.perc[,1]<=me & nor.perc[,2]>=me))
#Calculate the probability of the left side of the normal distribution
cat('norm.left=',mean(nor.norm[,1]>=me ),
    'basic.left =',mean(nor.basic[,1]>=me ),
    'perc.left =',mean(nor.perc[,1]>=me))
#Calculate the right side probability of a normal distribution
cat('norm.right=',mean(nor.norm[,2]<=me ),
    'basic.right =',mean(nor.basic[,2]<=me ),
    'perc.right =',mean(nor.perc[,2]<=me))
```

$\text{Chi-square distribution}$

Calculating true skewness using Monte Carlo method.

```{r}
pian.real<-mean(replicate(1000,expr = {
  x0<-rchisq(1000,5)
  mean((x0-5)^3)/10^1.5
}))
print(pian.real)
```

We take a sample with a normal distribution of $\chi^{2}(5)$, the sample size is 20, and each time we do bootstrap 1000 times, we cycle 1000 experiments. The coverage of the interval is calculated based on the experimental results.
```{r}
me<-pian.real
n<-20
m<-1000
set.seed(12345)
library(boot)
chi.norm<-chi.basic<-chi.perc<-matrix(NA,m,2)
for (i in 1:m) {
  data.chisq<-rchisq(n,5)
  chisq.ske<-boot(data.chisq,statistic=sk,R=1000)
  chi<- boot.ci(chisq.ske,type=c("norm","basic","perc"))
  chi.norm[i,]<-chi$norm[2:3];
  chi.basic[i,]<-chi$basic[4:5];
  chi.perc[i,]<-chi$percent[4:5];
}
#Calculate the coverage probability of the chi-square distribution
cat('norm =',mean(chi.norm[,1]<=me & chi.norm[,2]>=me),
    'basic =',mean(chi.basic[,1]<=me & chi.basic[,2]>=me),
    'perc =',mean(chi.perc[,1]<=me & chi.perc[,2]>=me))
#Calculate the probability of the left side of the chi-square distribution
cat('norm.left=',mean(chi.norm[,1]>=me ),
    'basic.left =',mean(chi.basic[,1]>=me ),
    'perc.left =',mean(chi.perc[,1]>=me))
#Calculate the right side probability of the chi-square distribution
cat('norm.right=',mean(chi.norm[,2]<=me ),
    'basic.right =',mean(chi.basic[,2]<=me ),
    'perc.right =',mean(chi.perc[,2]<=me))
```


$\textbf{Analysis}$:The coverage interval of the skewness of the normal distribution is much better than the chi-square distribution. The interval coverage probability of a normal distribution is greater than 0.9, and the chi-square distribution is approximately 0.7.

# The homework 7

## Questions

$\textbf{7.8}$Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat\theta.

$\textbf{7.10}$ In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Repeat the analysis replacing the Log-Log model with a cubic polynomial model. Which of the four models is selected by the cross validation procedure? Which model is selected according to maximum adjusted $R^{2}$ ?

## Process

## Question 7.8
Load the package and read in the data to calculate the data covariance matrix. Show the first five rows of data.

```{r}
library(bootstrap) #for the score data
cov(scor)
#show a part of data
scor[1:5,]
```
A function that defines a covariance matrix
```{r}
mcov <- function(x,j) cov(x[j,])
```

We obtain the jackknife estimates of bias and standard error of $\hat{\theta}$
```{r}
#Computing data dimension
n<-lengths(scor)[1]
#Calculate the real covariance matrix
real.cov <- mcov(scor,1:n)
#Calculate the real theta value
the.hat<-eigen(real.cov)$values[1]/sum(eigen(real.cov)$values)
#Define variables to store values
the.jack <- numeric(n)
#Loop n times
for(i in 1:n){
the.cov <- mcov(scor,(1:n)[-i])
#Get matrix eigenvalues
eig1<-eigen(the.cov)$values
#Find the estimate of lambda
the.jack[i]<-eig1[1]/sum(eig1)
}
#Calculation bias
bias1 <- (n-1)*(mean(the.jack)-the.hat)
#Calculating  standard deviation
se1 <- sqrt((n-1)*mean((the.jack-the.hat)^2))
round(c(original=the.hat,estimate=mean(the.jack),bias1=bias1,
se1=se1),3)
```

$\textbf{Analysis}$:The estimated value of lambda is 0.619.The deviation is only 0.001, it can be seen that the Jacknife method works better. The standard deviation value is 0.05


## Question 7.10
Define a function to calculate adjusted $R^{2}$
```{r}
r2<-function(x,y,p){
  a<-(n-2)*(sum((y-mean(x))^2)/sum((x-mean(x))^2))/(n-2-p)
}
```

Load package DAAG and get dataset.
```{r}
library(DAAG);
attach(ironslag);
```

I repeat the analysis replacing the Log-Log model with a cubic polynomial model.And I calculate $R^{2}$ of every method.
```{r}
n <- length(magnetic) #in DAAG ironslag
e1 <- e2 <- e3 <- e4 <- numeric(n)
# for n-fold cross validation
# fit models on leave-one-out samples
yhat1<-yhat2<-yhat3<-yhat4<-numeric(n)
for (k in 1:n) {
y <- magnetic[-k]
x <- chemical[-k]
#Linear model
J1 <- lm(y ~ x)
yhat1[k] <- J1$coef[1] + J1$coef[2] * chemical[k]
e1[k] <- magnetic[k] - yhat1[k]

#Quadratic model
J2 <- lm(y ~ x + I(x^2))
yhat2[k] <- J2$coef[1] + J2$coef[2] * chemical[k] +
J2$coef[3] * chemical[k]^2
e2[k] <- magnetic[k] - yhat2[k]

#Exponential model
J3 <- lm(log(y) ~ x)
logyhat3 <- J3$coef[1] + J3$coef[2] * chemical[k]
yhat3[k] <- exp(logyhat3)
e3[k] <- magnetic[k] - yhat3[k]

# cubic polynomial model
J4 <- lm(y ~ x+I(x^2)+I(x^3))
yhat4[k]<- J4$coef[1] + J4$coef[2]* chemical[k] +J4$coef[3]* chemical[k]^2+J4$coef[4]* chemical[k]^3
e4[k]<- magnetic[k] - yhat4[k]

}
#calculate R^2 of four methods
rsq1<-r2( magnetic,yhat1,1)
rsq2<-r2( magnetic,yhat2,2)
rsq3<-r2( magnetic,yhat3,1)
rsq4<-r2( magnetic,yhat4,3)
```

Output squared error and adjusted $R^{2}$ value of four methods.
```{r}
c(mean(e1^2), mean(e2^2), mean(e3^2), mean(e4^2))
c(rsq1,rsq2,rsq3,rsq4)
```

$\textbf{Analysis}$:The quadratic model has the smallest sum of squared errors, and the adjusted $R^{2}$ is the largest, so the quadratic model is the best model.




# The homework 8

## Questions
$\textbf{Question1:}$ 8.3 The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.

$\textbf{Question2:}$ Power comparison (distance correlation test versus ball covariance test)

1.Model 1: Y = X/4 + e

2.Model 2: Y = X/4 * e

3.$X ≥ N(0_{2},I_{2} )$, $e≥ N(0_{2},I_{2})$, X and e are independent.

## Question1
 $\textbf{Thought:}$Use two methods and take different values of n to show the results.
 
Method 1: Use the number of extreme values as statistics and take 6 different values of n. Draw a conclusion by comparing with the size of the original statistic,and the table shows the results.
Method 2: Use the results of extreme value tests as statistics, and take 6 different values of n. The conclusion is drawn by comparing with the size of the original statistic, and the results are plotted.
 
$\textbf{Method 1:}$

Writing Statistics Functions 
```{r}
rm(list = ls())
count5test <- function(z,ix,sizes) {
n11<-sizes[1]
n22<-sizes[2]
n0<-n11+n22
z<-z[ix]
x1<-z[1:n11]
y1<-z[(n11+1):n0]
X <- x1 - mean(x1)
Y <- y1- mean(y1)
outx <- sum(X > max(Y)) + sum(X < min(Y))
outy <- sum(Y > max(X)) + sum(Y < min(X))
# return 1 (reject) or 0 (do not reject H0)
return(max(c(outx, outy)))
}
```

Write functions and display them in tables
```{r}
library(boot)
n1<-30
n2<-c(30,40,50,60,70,80)
u1<-u2<-0
sig1<-1
sig2<-1
p.value<-numeric(6)
a=1
for (i in n2) {
   n3<-i
   size1<-c(n1,n3)
   x<-rnorm(n1,u1,sig1)
   y<-rnorm(n3,u2,sig2)
   z<-c(x,y)
   set.seed(4*i);
   boot.obj <- boot(data = z, statistic = count5test, R = 999, sim = "permutation",sizes=size1)
   ts <- c(boot.obj$t0,boot.obj$t)
   p.value[a]<- mean(ts>=ts[1])
   a=a+1
}
data.frame(n2,p.value)
```

$\textbf{Analysis:}$A value of p greater than 0.05 indicates that there is no sufficient reason to reject the null hypothesis and that their variances are the same.

$\textbf{Method 2:}$
 
Writing Statistics Functions
```{r}
rm(list = ls())
count5test <- function(z,ix,sizes,kk) {
n11<-sizes[1]
n22<-sizes[2]
n0<-n11+n22
z<-z[ix]
x1<-z[1:n11]
y1<-z[(n11+1):n0]
X <- x1 - mean(x1)
Y <- y1- mean(y1)
outx <- sum(X > max(Y)) + sum(X < min(Y))
outy <- sum(Y > max(X)) + sum(Y < min(X))
# return 1 (reject) or 0 (do not reject H0)
return(as.integer(max(c(outx, outy))>kk))
}
```

Write functions and represent results with images
```{r}
library(boot)
n1<-30
n2<-c(35,40,50,60,70,80)
u1<-u2<-0
sig1<-1
sig2<-1
p.value2<-numeric(6)
a=1
for (i in n2) {
   n3<-i
   size1<-c(n1,n3)
   x<-rnorm(n1,u1,sig1)
   y<-rnorm(n3,u2,sig2)
   z<-c(x,y)
   set.seed(i);
   boot.obj <- boot(data = z, statistic = count5test, R = 999, sim = "permutation",sizes=size1,kk=a+4)
   ts <- c(boot.obj$t0,boot.obj$t)
   p.value2[a] <- mean(ts!=ts[1])
   a<-a+1
}
data.frame(n2,p.value2)
plot(n2,p.value2,type = 'o',col='red',ylim = c(0,1))
```

$\textbf{Analysis:}$When n1 = n2, the p value of the statistic is small, but as the sample size increases, the p value gradually decreases, which is not as good as the first method.When n increases, we will increase the value of kk appropriately will have a good effect.

## Question2

$\textbf{Thought:}$Compare the superiority of the two methods under different models. When the value of power is larger, the effect is better. Because the Ball method works well when the variance is large, the ball covariance test statistic is more dominant in the second model.

Writing the calling function
```{r}
dCov <- function(x, y) {
    x <- as.matrix(x); y <- as.matrix(y)
    n <- nrow(x); m <- nrow(y)
    if (n != m || n < 2) stop("Sample sizes must agree")
    if (! (all(is.finite(c(x, y)))))
    stop("Data contains missing or infinite values")
    Akl <- function(x) {
        d <- as.matrix(dist(x))
        m <- rowMeans(d); M <- mean(d)
        a <- sweep(d, 1, m); b <- sweep(a, 2, m)
        b + M
    }
    A <- Akl(x); B <- Akl(y)
    sqrt(mean(A * B))
}

```

Double loop, and get the power of the two models in two ways.
```{r cars}
library(MASS)
library(Ball)
#options(digits=3)
alpha=0.1
mean <- c(0,0)
sigma <- matrix(c(1,0,0,1),nrow=2,ncol=2)
cn<-c(10,20,30,40,50,60,80,100)
p.value1 <- matrix(NA,8,4)
a=1

ndCov2 <- function(z, ix, dims) {
    #dims contains dimensions of x and y
    p <- dims[1]
    q <- dims[2]
    d <- p + q
    x0 <- z[, 1:p] #leave x as is
    y0 <- z[ix, -(1:p)] #permute rows of y
    return(nrow(z) * dCov(x0, y0)^2)
}

for (i in cn) { 
    p.cor1<-numeric(50)
    p.cor2<-numeric(50)
    p.cor3<-numeric(50)
    p.cor4<-numeric(50)
  for (j in 1:50) {
      
    xn<-mvrnorm(n=i,mean,sigma)
    en<-mvrnorm(n=i,mean,sigma)
    yn1<-xn/4+en
    yn2<-xn/4*en
    set.seed(12345)
    
    z1 <- cbind(xn,yn1)
    boot.obj1 <- boot(data = z1, statistic = ndCov2, R = 199,sim = "permutation", dims = c(2, 2))
    tb1 <- c(boot.obj1$t0, boot.obj1$t)
    p.cor1[j]<- mean(tb1>=tb1[1])
    p.cor3[j]<-bcov.test(x = xn, y = yn1, R=999,seed =i*1234*j)$p.value
    z2 <- cbind(xn,yn2)
    boot.obj2<- boot(data = z2, statistic = ndCov2, R = 199,sim = "permutation", dims = c(2, 2))
    tb2 <- c(boot.obj2$t0, boot.obj2$t)
    p.cor2[j] <- mean(tb2>=tb2[1])
    p.cor4[j] <-bcov.test(x = xn,y =yn2,R=999,seed = i*1233*j)$p.value
  }
  p.value1[a,1]<-mean(p.cor1<alpha)
  p.value1[a,2]<-mean(p.cor3<alpha)
  p.value1[a,3]<-mean(p.cor2<alpha)
  p.value1[a,4]<-mean(p.cor4<alpha)
  a=a+1
  print(a)
}
par(mar=c(1,1,1,1))
par(mfrow=c(1,2))
    plot(cn,p.value1[,1],type='l',col='red',ylim = c(0,1))
    lines(cn,p.value1[,2],type='l',col='yellow')
    plot(cn,p.value1[,3],type='l',col='red',ylim = c(0,1))
    lines(cn,p.value1[,4],type='l',col='yellow')
```

$\textbf{Analysis:}$In the first model, the variance is not large, so the first method distance correlation test is better and more reliable. But in the second model, the variance is large, so the ball covariance test is better. When the sample size increases, the value of power both increases.




# The homework 9

## Question

Implement a random walk Metropolis sampler for generating the standard Laplace distribution (see Exercise 3.2). For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.

## Program

The following function uses the Metropolis sampler method to calculate a Markov sequence.
```{r}
rp.Metropolis <- function(sigma, x0, N) {
x <- numeric(N)
x[1] <- x0
u <- runif(N)
k <- 0
for (i in 2:N) {
y <- rnorm(1, x[i-1], sigma)
#Replace probability density function with Laplace distribution
if (u[i] <= (0.5*exp(-abs(y))) / (0.5*exp(-abs(x[i-1]))))
    x[i] <- y 
else {
    x[i] <- x[i-1]
    k <- k + 1
}
}
return(list(x=x, k=k))
}
```

Take different variances and observe when it is stable and the acceptance probability under different variances.
```{r}
N <- 2000
sigma <- c(.2, .5, 2, 16)
x0 <- 25
#Get the return value of different variances
rp1 <- rp.Metropolis(sigma[1], x0, N)
rp2 <- rp.Metropolis(sigma[2], x0, N)
rp3 <- rp.Metropolis(sigma[3], x0, N)
rp4 <- rp.Metropolis(sigma[4], x0, N)
#Calculate acceptance probability
p1<-1-rp1$k/N
p2<-1-rp2$k/N
p3<-1-rp3$k/N
p4<-1-rp4$k/N
data.frame(p1,p2,p3,p4)
```
A bigger problem is calculating the 0.025 and 0.975 quantiles. We need to solve the values of the independent variables when the distribution function is equal to 0.025 and 0.975.
$$0.025=\int_{-\infty}^{x_{1}} \frac{1}{2} e^{-| t |} d t$$
$$0.975=\int_{0}^{x_{2}} \frac{1}{2} e^{-| t |} d t+0.5$$
And we get $x_{1}=log(0.05)$ ,$x_{2}=-log(0.05)$.

Then we draw a Markov sequence diagram and mark 0.025 and 0.975 quantiles with horizontal lines

```{r}
   
    par(mar=c(1,1,1,1))
    par(mfrow=c(2,2))  #display 4 graphs together
    refline <- c(log(0.05),-log(0.05))
    rp <- cbind(rp1$x, rp2$x, rp3$x,  rp4$x)
    for (j in 1:4) {
        plot(rp[,j], type="l",
             xlab=bquote(sigma == .(round(sigma[j],3))),
             ylab="X", ylim=c(-5,30),col='blue')
        abline(h=refline,col='red')
    }
    
```

$\textbf{Analysis:}$

1.When different variances are used for the proposal distribution,They have different descent rates.The larger the variance, the faster the convergence. When the variance is small, it takes a long time to converge. When the variance is too large, the time in the same state is too long, and the efficiency is low.

2.The smaller the variance, the easier it is to reject the expected probability; the smaller the variance, the easier it is to accept the probability of acceptance.



# The homework 10

## Questions
$\textbf{11.1}$.The natural logarithm and exponential functions are inverses of each other, so that mathematically log(expx) = exp(logx) = x. Show by example that this property does not hold exactly in computer arithmetic. Does the identity hold with near equality? (See all.equal.)

$\textbf{11.5}$.Write a function to solve the equation
$$
\begin{aligned} \frac{2 \Gamma\left(\frac{k}{2}\right)}{\sqrt{\pi(k-1)} \Gamma\left(\frac{k-1}{2}\right)} \int_{0}^{c_{k-1}}\left(1+\frac{u^{2}}{k-1}\right)^{-k / 2} d u \\=& \frac{2 \Gamma\left(\frac{k+1}{2}\right)}{\sqrt{\pi k} \Gamma\left(\frac{k}{2}\right)} \int_{0}^{c_{k}}\left(1+\frac{u^{2}}{k}\right)^{-(k+1) / 2} d u \end{aligned}
$$

for a,where 
$$c_{k}=\sqrt{\frac{a^{2}k}{k+1-a^{2}}}$$
Compare the solutions with the points A(k) in Exercise 11.4.

$\textbf{Question3:}$

![Question3](ww1.png)

## Question 1
Randomly take numbers from 0 to 1000 to get equal probability.
```{r }
seq1<-seq(1,100,1)
tr1<-tr2<-numeric(length(seq1))
wf<-function(i){
return(exp(log(i))==log(exp(i)))}
dx<-function(i){
  isTRUE(all.equal(exp(log(i)),log(exp(i))))
}
for (i in seq1){
  tr1[i]<-wf(i)
  tr2[i]<-dx(i)
}
mean(tr1)
mean(tr2)
```
29% of the values show that the results are not equal.Different value ranges will have different equal probabilities.But using the function all.equal gives the result of equal probability 1.

## Question 2
First define the function to be called.
```{r }
rm(list=ls())
k=4
ck<-function(k,a){
  return(sqrt(a^2*k/(k+1-a^2)))
  }
wf1 <- function(u) {
(1+u*u/(k-1))^(-k/2)
}
wf2<- function(u) {
(1+u*u/k)^(-(k+1)/2)
}
wf3<-function(a){
  2*gamma(k/2)/(sqrt(pi*(k-1))*gamma((k-1)/2))*integrate(wf1,0,ck(k-1,a))$value-2*gamma((k+1)/2)/(sqrt(pi*k)*gamma(k/2))*integrate(wf2,0,ck(k,a))$value
}
```

Calculate 11.5, the root value of a under different values of k.
```{r}
kt<-c(seq(4,25,1),100,200)
solution11.5<-solution11.4<-numeric(length(kt))
js=1
for (i in kt) {
  k<-kt[js]
  solution11.5[js]<-uniroot(wf3,c(0.001,sqrt(k)/2+1))$root
  js=js+1
}
```
Calculate 11.4, the root value of a with different values of k
```{r}
js=1
wf4<-function(a){pt(sqrt(a^2*(k-1)/(k-a^2)),k-1)-pt(sqrt(a^2*k/(k+1-a^2)),k)}
for (i in kt) {
   k<-kt[js]
  solution11.4[js]<-uniroot(wf4,c(0.00001,sqrt(k)-0.0001))$root
  js=js+1
}
data.frame(kt,solution11.4,solution11.5)
```

Analysis:These two questions almost give the same results using both methods.

## Question 3
Iterative formula for calculating p and q：
Let x and t be equal to:

$$x=\frac{\frac{n_{B}q_{i}}{2-q_{i}-2p_{i}}+n_{B}+n_{AB}}{\frac{n_{A}p_{i}}{2-p_{i}-2q_{i}}+n_{A}+n_{AB}}$$
$$t=\frac{(1-\frac{p_{i}}{2-p_{i}-2q_{i}})n_{A}+(1-\frac{q_{i}}{2-2p_{i}-q_{i}})n_{B}+2n_{oo}}{\frac{n_{B}q_{i}}{2-q_{i}-2p_{i}}+n_{B}+n_{AB}}$$




# The homework 11

## Question

$\textbf{Question1:}$Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:

    formulas <- list(
    mpg ~ disp,
    mpg ~ I(1 / disp),
    mpg ~ disp + wt,
    mpg ~ I(1 / disp) + wt
    )
    
$\textbf{Question2:}$Fit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below by using a for loop and lapply() .
Can you do it without an anonymous function?

    bootstraps <- lapply(1:10, function(i) {
    rows <- sample(1:nrow(mtcars), rep = TRUE)
    mtcars[rows, ]
    })
    
$\textbf{Question3:}$ For each model in the previous two exercises, extract R 2 using the function below.

    rsq <- function(mod) summary(mod)$r.squared
    
$\textbf{Question4:}$
The following code simulates the performance of a t-test for
non-normal data. Use sapply() and an anonymous function
to extract the p-value from every trial.
    trials <- replicate(
    100,
    t.test(rpois(10, 10), rpois(7, 10)),
    simplify = FALSE
    )
Extra challenge: get rid of the anonymous function by using [[ directly.
$\textbf{Question5:}$Implement mcsapply() , a multicore version of sapply() . Can you implement mcvapply() , a parallel version of vapply() ?
Why or why not?
    
## Program

## Question 1
The first method, using a for loop and lapply respectively.
```{r}
formulas1<- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)
j=1:4
li=list()
#Use lapply
la<-lapply(j,function(j)lm(formulas1[[j]],data = mtcars))
la

#Or use a for loop
for (j in 1:4) {
  li[[j]]<-lm(formulas1[[j]],data = mtcars)
}
li
```

The second method, using a for loop and lapply respectively
```{r }
rm(list = ls())
formulas <- list(
l1<-function(mtcars) glm(mtcars$mpg ~ mtcars$disp),l2<-function(mtcars) glm(mtcars$mpg ~ I(1 / mtcars$disp)),l3<-function(mtcars) glm(mtcars$mpg ~ mtcars$disp + mtcars$wt),l4<-function(mtcars) glm(mtcars$mpg ~ I(1 / mtcars$disp) +mtcars$wt)
)
#Use lapply
la1<-lapply(formulas, function(f) f(mtcars))

#Or use a for loop
li1=list()
for (i in 1:4){
  #li1<-list(li1,formulas[[i]](mtcars))
  li1[[i]]<-formulas[[i]](mtcars)
}
```


## Question 2
The first method, using a for loop and lapply respectively.
```{r}
formulas1<- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)
  bootstraps <- lapply(1:10, function(i) {
  rows <- sample(1:nrow(mtcars), rep = TRUE)
  mtcars[rows, ]
  })
li0=list()
#Use lapply
j=1:10
la0<-lapply(j,function(j)lm(formulas1[[1]],data = bootstraps[[j]]))
la0
#Or use a for loop
for (j in 1:10) {
  li0[[j]]<-lm(formulas1[[1]],data = bootstraps[[j]])
}
li0
```
The second method, using a for loop and lapply respectively
```{r}
#Use lapply
la2<-lapply(bootstraps,formulas[[1]])
li2<-list()
#Or use a for loop
for (i in 1:10) {
  li2[[i]]<-formulas[[1]](bootstraps[[i]])
}
```


## Question3

## For the first model
```{r }
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)
wf <- numeric(4)
rsq <- function(mod) summary(mod)$r.squared
j = 1:4
wf <- lapply(j,function(j) {rsq(lm(formulas[[j]], data = mtcars))})
wf
```

## For the second model
```{r }
bootstraps <- lapply(1:10, function(i) {
  rows <- sample(1:nrow(mtcars), rep = TRUE)
  mtcars[rows, ]
  })
wf <- numeric(10)
rsq <- function(mod) summary(mod)$r.squared
j = 1:10
wf <- lapply(j,function(j) {rsq(lm(formulas[[1]], data = bootstraps[[j]]))})
wf

```

## Question 4

```{r}
trials2 <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)
tq<-function(a)a$p.value
sapply(trials2,tq)
```

## Extra challenge:

```{r}
sapply(trials2,"[[",3)
```

## Question 5
```{r }
library(parallel)
formulas <- list(
l1<-function(mtcars) glm(mtcars$mpg ~ mtcars$disp),l2<-function(mtcars) glm(mtcars$mpg ~ I(1 / mtcars$disp)),l3<-function(mtcars) glm(mtcars$mpg ~ mtcars$disp + mtcars$wt),l4<-function(mtcars) glm(mtcars$mpg ~ I(1 / mtcars$disp) +mtcars$wt)
)
cl<-makeCluster(4)
bootstraps2 <- lapply(1:3000, function(i) {
  rows <- sample(1:nrow(mtcars), rep = TRUE)
  mtcars[rows, ]})
system.time(sapply(bootstraps2,formulas[[1]]))
system.time(parSapply(cl,bootstraps2,formulas[[1]]))
```

$\mathbf{Analysis:}$It can be seen from the results that multi-core is significantly faster than using the sapply function alone. I don't think you can use multi-core for vapply because it cannot be unlisted.

# The homework 12

## Question

  You have already written an R function for Exercise 9.4 (page
277, Statistical Computing with R). Rewrite an Rcpp function
for the same task.
  Compare the generated random numbers by the two functions
using qqplot.
  Campare the computation time of the two functions with
microbenchmark.
  Comments your results.

## Program 

This is the r language code for exercise 9.4
 
```{r}
rp.Metropolis <- function(sigma, x0, N) {
x <- numeric(N)
x[1] <- x0
u <- runif(N)
k <- 0
for (i in 2:N) {
   y <- rnorm(1, x[i-1], sigma)
   #Replace probability density function with Laplace distribution
   if (u[i] <= (0.5*exp(-abs(y))) / (0.5*exp(-abs(x[i-1]))))
       x[i] <- y 
   else {
       x[i] <- x[i-1]
       k <- k + 1
        }
     }
return(list(x=x, k=k))
}
```

Write c language code with cppfunction function in r as follows.

```{r}
library(Rcpp)
cppFunction('NumericVector rp(double sigma,double xx,int N){
#include<Rcpp.h>
NumericVector x(N+1);
x[0]=xx;
int k=0;
for(int i=1;i<N;++i){
  srand(i);
  double u=rand()/(RAND_MAX+1.0);
  double y=as<double>(rnorm(1, x[i-1], sigma));
    if(u<=(0.5*exp(-abs(y)))/(0.5*exp(-abs(x[i-1]))))
        {x[i]=y;}
    else{
        x[i]=x[i-1];
            k=k+1;
            }
}
x[N]=k;
return x;
}
            ')
```

Write function comparison of output efficiency and probability of rejection

```{r}
N <- 2000
sigma <- c(3, 5, 10, 16)
library(car)
x0 <-5
library(microbenchmark)

pic<-function(i){
ts <- microbenchmark(rp1 <- rp.Metropolis(sigma[i], x0, N),rpp1 <- rp(sigma[i], x0, N))
tsr<-summary(ts)[,c(1,3,5,6)]
#rpp1
par(mar=c(1,1,1,1))
par(mfrow=c(2,2))
#qqnorm(rp1$x,col='green')
#qqline(rp1$x,col='red')
#qqnorm(rpp1[1:N],col='green')
#qqline(rpp1[1:N],col='red')
qqplot(rp1$x,rpp1[1:N],col='green')
qqline(rpp1[1:N],col='red')
return(list(rpp1[N+1],tsr))
}
```

Draw qqplot plots with different variances

```{r}
par(mar=c(1,1,1,1))
par(mfrow=c(2,2))
for (i in 1:4) {
  res<-pic(i)
  print("Probability of rejection")
  print(res[1])
  print("Comparison of the two methods")
  print(res[2])
  
}
```

$\textbf{Analysis:}$It can be seen from qqlot that the two methods are from the same distribution and are approximately straight lines. In addition, the use of C language will greatly speed up the operation.C language only takes one tenth of the time of r language


